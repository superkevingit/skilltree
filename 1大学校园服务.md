#大学校园服务

### Lab

一个校园服务的爬虫项目，自己写的很多校内的应用都是建立在这个服务之上的。

### 项目地址

https://github.com/EcjtuNet/SchoolServiceAPI

### 解释

大部分的东西都能在项目的readme中看到，包括完成的功能、待完成的功能，是一个从0开始写的爬虫程序，许多东西也是边学边改的。

### 依赖

flask：一个轻量的web框架，做简单的http路由接口

peewee：orm框架，简单的数据关系映射，管理用户基本信息

requests：一个python数据请求的库，爬虫的基础

bs4:一个python解析html元素的库，配合正则re库实用，过滤信息

### 文件组织 (2017.2)

app.py 程序主入口，此文件定义了所有的路由

login.py 爬虫登录模块，获取登录cookies

node_server/ 处理一个登陆时的前端加密工作，出此下策

analyse.py 爬虫抓取信息模块，定义不同信息获取的方法

user.py 用户映射表，相当于model层，因为简单，未单独建立目录

deploy.py 启动项目前运行的模块，初始化数据库，爬取用户基本信息

config.py 配置文件，一些配置参数，还有一些是代码运行定义的变量规范

\>>>>> 

apiary.apib 接口文档蓝图，在apiary网站生成

gunicorn.py gunicorn配置文件

ss_supervisor.conf supervisor配置文件

ss_nginx.conf nginx配置文件

requirements.txt pip依赖配置文件

run/ 运行时pid文件目录

logs/ gunicorn运行日志

data_manage/ 整合数据时使用的脚本，可忽略

### 可能需要提及的Tricks

1.学校的校园服务原本是分散的，可是在我大二的时候开始做了新系统，而且主导项目的老师比较6，把一些老的应用和新应用做了sso，通过cas入口就可以进入几乎所有的校园web程序。于是我就想，我这下只需要解决一个登陆就可以把校园服务整合起来，然后做很多有用好玩的东西了。

2.然后就是研究登陆页面，抓包分析发现提交密码比较诡异，后发现是使用js前端加密了密码然后提交给后端。当时寻找了好些办法，比如什么pyv8引擎模拟浏览器行为，想想这些总感觉不太靠谱。正好当时看了nodejs，于是就想出把前端加密的代码扒出来，然后改改用node解析，维护一个内部接口，专门返回加密后的密码（哈哈，这下我也有一个密码加密服务了），使用pm运行了node，目前没发现这一模块的报错问题

3.登陆教务系统发现可以查到近几年的所有班级学生的姓名学号和班级编号，于是用登陆的账号密码单独放在配置文件里，使得只要配置一个能登陆教务系统的账号，就能把所有班级名单爬下来，这就做好了基础人员信息的收集。（爬取人员的时候做了好多好玩的事情，写过爬虫的同学应该都能明白）

### 还要做什么呢

1. 因为服务是挂在社团服务器上的，属于学校内网。可是学校老师比较不友好，经常以我们发包太多，带宽太大把我们的网给关了。于是在研究一个ip池的项目，也是一个爬虫项目，但比这个爬虫项目不稳定因素比较多，研究会延后一些。

2. 打算自己也做一个sso，维护一套自己的项目群，然后使用这个项目的用户群做信息授权端。




